# -*- coding: utf-8 -*-
"""all_functions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_KyfQ03j0yM9boJ8XEytShMGohrQrtJR
"""

# pip install imbalanced-learn
# pip install --upgrade pandas
# pip install optuna
# pip install xgboost
# pip install python-dotenv

import pandas as pd
import numpy as np
import os
from dotenv import load_dotenv
import warnings
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold
from imblearn.over_sampling import SMOTENC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, make_scorer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.utils.multiclass import unique_labels
import pickle
import optuna
from xgboost import XGBClassifier
from sklearn.decomposition import PCA

warnings.filterwarnings('ignore')

"""#Load Data and Check Null Values"""

def load_and_analyze_data(filepath):
    """
    Load data from a CSV file, select numerical types and analyze for null values.

    Parameters:
    - filepath: str, path to the CSV file

    Returns:
    - num_dataset: DataFrame, dataset containing only numerical columns
    """
    # Load Data
    dataset = pd.read_csv(filepath)

    # Select only numeric data types
    num_dataset = dataset.select_dtypes(include=[np.number])

    # Return the numeric dataset
    return num_dataset, dataset

"""#Multivariate Analysis"""

def rank_columns_by_correlation(df, threshold):
    """
    Calculate the correlation matrix for a DataFrame and return a DataFrame
    listing column pairs with correlations above a specified threshold.

    Parameters:
    - df: DataFrame, the dataset whose numerical columns are to be analyzed.
    - threshold: float, the minimum absolute correlation coefficient to include in the results.

    Returns:
    - correlation_df: DataFrame, containing pairs of highly correlated columns and their correlation coefficients.
    """
    # Calculating the correlation matrix
    corr_matrix = df.corr()

    # Initializing a list to hold tuples of highly correlated columns
    correlations = []

    # Iterating over the correlation matrix, avoiding self-correlation and duplicates
    for i in range(len(corr_matrix.columns)):
        for j in range(i + 1, len(corr_matrix.columns)):
            # Including only correlations above the specified threshold
            if abs(corr_matrix.iloc[i, j]) > threshold:
                correlations.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))

    # Sorting the list by absolute correlation in descending order
    sorted_correlations = sorted(correlations, key=lambda x: abs(x[2]), reverse=True)
    correlation_df = pd.DataFrame(sorted_correlations, columns=['Column1', 'Column2', 'Correlation'])

    return correlation_df

def remove_correlated_features(dataset, top_correlations):
    """
    Remove one of each pair of highly correlated features from a DataFrame based on provided correlation data.

    Parameters:
    - dataset: DataFrame, the original dataset from which features are to be removed.
    - top_correlations: DataFrame, contains the pairs of correlated features.

    Returns:
    - dataset: DataFrame, the dataset with selected features removed.
    """
    # Extracting column names to remove (choosing 'Column2' from each pair)
    columns_to_remove = top_correlations["Column2"].unique()

    # Removing the columns from the dataset
    dataset.drop(columns=columns_to_remove, axis="columns", inplace=True)
    return dataset

"""#Test Train Split"""

def split_data(dataset, split_year):
    """
    Splits the dataset into training and testing sets based on a specified year.

    Parameters:
    - dataset: DataFrame, the full dataset containing a 'year' column and target column.
    - split_year: int, the year at which the dataset is divided into training and testing sets.

    Returns:
    - X_train: DataFrame, the training data features.
    - y_train: Series, the training data target.
    - X_test: DataFrame, the testing data features.
    - y_test: Series, the testing data target.
    """
    # Data separation by year
    training_data = dataset.loc[dataset["year"] < split_year - 1]
    testing_data = dataset.loc[(dataset["year"] == split_year - 1) | (dataset["year"] == split_year)]

    # Predictor - Target Split
    X_train = training_data.drop("dps_change_next_year", axis="columns")
    y_train = training_data["dps_change_next_year"]
    X_test = testing_data.drop("dps_change_next_year", axis="columns")
    y_test = testing_data["dps_change_next_year"]

    return X_train, y_train, X_test, y_test

"""#Data Pre-Processing, Encode Categorical Features, Normalize Feature Values"""

def preprocess_data(X_train, X_test, categorical_columns):
    """
    Processes the training and testing data using a pipeline that includes label encoding for
    categorical variables and scaling for all features.

    Parameters:
    - X_train: DataFrame, the training data.
    - X_test: DataFrame, the testing data.
    - categorical_columns: list, a list of column names in the DataFrame that are categorical.

    Returns:
    - X_train_transformed: DataFrame, the processed training data.
    - X_test_transformed: DataFrame, the processed testing data.
    """
    # Define other columns based on categorical columns
    other_columns = [col for col in X_train.columns if col not in categorical_columns]

    # Set up the preprocessing steps: Ordinal encoding for categorical and scaling for all
    column_transformer = ColumnTransformer(
        transformers=[
            ('categorical', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_columns)
        ],
        remainder='passthrough'
    )

    # Create a pipeline to prevent data leakage
    pipeline_preprocess = Pipeline([
        ('transformer', column_transformer),
        ('scaler', StandardScaler())
    ])

    # Apply the pipeline to training and testing datasets
    X_train_transformed = pipeline_preprocess.fit_transform(X_train)
    X_test_transformed = pipeline_preprocess.transform(X_test)

    # Convert numpy arrays back to DataFrame and reassign column names
    X_train_transformed = pd.DataFrame(X_train_transformed, columns=categorical_columns + other_columns, index=X_train.index)
    X_test_transformed = pd.DataFrame(X_test_transformed, columns=categorical_columns + other_columns, index=X_test.index)

    # Optional: Convert data types back to their original forms, if necessary
    cols_to_convert = {col: 'int' if col in categorical_columns else 'float' for col in categorical_columns + other_columns}
    X_train_transformed = X_train_transformed.astype(cols_to_convert)
    X_test_transformed = X_test_transformed.astype(cols_to_convert)

    return X_train_transformed, X_test_transformed

"""#Stratified Cross-Validation and Smote Oversampling"""

# def perform_stratified_cv_with_smote(X, y, categorical_columns, n_splits=5, random_state=42):
#     """
#     Performs stratified cross-validation with SMOTE oversampling on a given dataset.

#     Parameters:
#     - X: DataFrame, the feature set.
#     - y: Series, the target variable.
#     - categorical_columns: list, a list of column names that are categorical.
#     - n_splits: int, number of folds for cross-validation.
#     - random_state: int, a seed for random operations to ensure reproducibility.

#     Returns:
#     - X_train_oversampled: DataFrame, the oversampled training features.
#     - y_train_oversampled: Series, the oversampled training target.
#     """
#     # Initialize the StratifiedKFold object
#     kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)

#     # Get categorical indices for SMOTE
#     categorical_indices = [X.columns.get_loc(col) for col in categorical_columns]

#     # Initialize SMOTE for categorical features
#     smote = SMOTENC(random_state=random_state, categorical_features=categorical_indices)

#     # Start the cross-validation process
#     for train_index, test_index in kf.split(X, y):
#         X_train, X_test = X.iloc[train_index], X.iloc[test_index]
#         y_train, y_test = y.iloc[train_index], y.iloc[test_index]

#         # Apply SMOTE to the training data
#         X_train_oversampled, y_train_oversampled = smote.fit_resample(X_train, y_train)

#         # Output the result of SMOTE
#         print("Counts of target classes after SMOTE:")
#         print(pd.DataFrame(y_train_oversampled).value_counts())

#         # Additional operations such as fitting a model can be added here

#     return X_train_oversampled, y_train_oversampled

def perform_stratified_cv_with_smote(X, y, categorical_columns, n_splits=5, random_state=42):
    """
    Performs stratified cross-validation with SMOTE oversampling on a given dataset.
    Applies SMOTE only when more than one class is present.
    """
    unique_classes = unique_labels(y)
    if len(unique_classes) > 1:
        kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)
        categorical_indices = [X.columns.get_loc(col) for col in categorical_columns]
        smote = SMOTENC(random_state=random_state, categorical_features=categorical_indices)
        for train_index, test_index in kf.split(X, y):
            X_train, X_test = X.iloc[train_index], X.iloc[test_index]
            y_train, y_test = y.iloc[train_index], y.iloc[test_index]
            X_train_oversampled, y_train_oversampled = smote.fit_resample(X_train, y_train)
            print("SMOTE applied. Counts of target classes after SMOTE:")
            print(pd.DataFrame(y_train_oversampled).value_counts())
        return X_train_oversampled, y_train_oversampled
    else:
        print("SMOTE not applied. Not enough classes.")
        return X, y  # Return original datasets without oversampling

"""#Feature Selection"""

def feature_importance_analysis(X_train, y_train, importance_threshold=0.60):
    """
    Performs feature importance analysis using a RandomForestClassifier and selects features based on cumulative importance.

    Parameters:
    - X_train: DataFrame, training data features.
    - y_train: Series, training data target.
    - importance_threshold: float, threshold for cumulative importance to select features (default is 60%).

    Returns:
    - selected_features: list, features that contribute to the top specified percentage of importance.
    - importance_table: DataFrame, table with features and their importance scores.
    """
    # Initialize and train the RandomForest model
    randomForestModel = RandomForestClassifier(max_features=None)
    randomForestModel.fit(X_train, y_train)

    # Extract feature importance
    feature_importances = randomForestModel.feature_importances_
    features = X_train.columns
    importance_table = pd.DataFrame({
        'Feature': features,
        'Importance': feature_importances
    })

    # Sort by importance
    importance_table.sort_values(by='Importance', ascending=False, inplace=True)

    # Calculate cumulative importance
    importance_table['Cumulative Importance'] = importance_table['Importance'].cumsum()

    # Find the last acceptable feature based on the importance threshold
    cutoff_index = importance_table[importance_table['Cumulative Importance'] <= importance_threshold].last_valid_index()
    selected_features = importance_table.loc[:cutoff_index, 'Feature'].tolist() if cutoff_index is not None else importance_table['Feature'].tolist()

    return selected_features, importance_table

"""#Feature Engineering(PCA)"""

def apply_pca(X_train, X_test, selected_features, variance_threshold=0.95):
    """
    Applies PCA on the training and testing datasets after restricting them to selected features.

    Parameters:
    - X_train: DataFrame, training data.
    - X_test: DataFrame, testing data.
    - selected_features: list, features selected based on importance or other criteria.
    - variance_threshold: float, the amount of variance that PCA should maintain.

    Returns:
    - X_train_pca: ndarray, PCA-transformed training dataset.
    - X_test_pca: ndarray, PCA-transformed testing dataset.
    - explained_variance: ndarray, amount of variance explained by each of the selected components.
    """
    # Select the relevant features
    X_train_selected = X_train[selected_features]
    X_test_selected = X_test[selected_features]

    # Initialize PCA and fit on the training data
    pca = PCA()
    pca.fit(X_train_selected)

    # Plot the cumulative explained variance to determine the number of components
    # plt.figure(figsize=(8, 4))
    # plt.plot(np.cumsum(pca.explained_variance_ratio_))
    # plt.xlabel('Number of Components')
    # plt.ylabel('Cumulative Explained Variance')
    # plt.title('Explained Variance by PCA Components')
    # plt.grid(True)
    # plt.show()

    # Apply PCA with the specified variance threshold
    pca = PCA(n_components=variance_threshold)
    X_train_pca = pca.fit_transform(X_train_selected)
    X_test_pca = pca.transform(X_test_selected)
    explained_variance = pca.explained_variance_ratio_

    return X_train_pca, X_test_pca, explained_variance

"""#Evaluation"""

def load_models(model_paths):
    models = {}
    for model_name, path in model_paths.items():
        with open(path, 'rb') as file:
            models[model_name] = pickle.load(file)
    return models

def evaluate_models(models, X_train, y_train, X_test, y_test):
    """
    Evaluates multiple models by fitting them on training data, predicting probabilities on test data,
    comparing predicted results with actual results, and computing the ROC AUC score for each.

    Parameters:
    - models: dict, a dictionary of models where keys are model names and values are the model instances.
    - X_train: array-like, training features.
    - y_train: array-like, training target.
    - X_test: array-like, testing features.
    - y_test: array-like, testing target.

    Returns:
    - result_df: DataFrame, a DataFrame containing actual values, predicted probabilities and model comparisons.
    """
    predictions = {'Actual': y_test}
    performances = {}
    # print("Testing Performances...Please wait")

    for model_name, model in models.items():
      if model_name == 'XGBoost':
        # Fit and transform the labels in the training data
        y_train = label_encoder.fit_transform(y_train)

        # Transform the labels in the test data
        y_test = label_encoder.transform(y_test)
      else:
        # Fit the model
        model.fit(X_train, y_train)

      # Predict probabilities
      predicted_probs = model.predict_proba(X_test)[:, 1]
      predictions[f'Predicted_Prob_{model_name}'] = predicted_probs

      # Compute ROC AUC score
      roc_auc = roc_auc_score(y_test, predicted_probs)
      performances[model_name] = roc_auc
      # print(f"{model_name} ROC AUC: {roc_auc:.4f}")

    # Create a DataFrame from the predictions dictionary
    result_df = pd.DataFrame(predictions)

    # Add a summary of performances at the end of the DataFrame
    performance_summary = pd.DataFrame([performances], index=['ROC AUC Score'])

    return result_df, performance_summary

